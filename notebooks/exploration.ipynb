{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b46c554",
   "metadata": {},
   "source": [
    "### Exploration of the dataset and the early stage modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d2c4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "import evaluate\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, pipeline, DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26f2fab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 287113/287113 [00:26<00:00, 10724.19 examples/s]\n",
      "Generating validation split: 100%|██████████| 13368/13368 [00:00<00:00, 36199.16 examples/s]\n",
      "Generating test split: 100%|██████████| 11490/11490 [00:00<00:00, 38281.66 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 287113\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 13368\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 11490\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "## import dataset from huggingface\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b65d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTICLE:\n",
      " (CNN)He's a blue chip college basketball recruit. She's a high school freshman with Down syndrome. At first glance Trey Moses and Ellie Meredith couldn't be more different. But all that changed Thursday when Trey asked Ellie to be his prom date. Trey -- a star on Eastern High School's basketball team in Louisville, Kentucky, who's headed to play college ball next year at Ball State -- was originally going to take his girlfriend to Eastern's prom. So why is he taking Ellie instead? \"She's great... she listens and she's easy to talk to\" he said. Trey made the prom-posal (yes, that's what they are calling invites to prom these days) in the gym during Ellie's P.E. class. Trina Helson, a teacher at Eastern, alerted the school's newspaper staff to the prom-posal and posted photos of Trey and Ellie on Twitter that have gone viral. She wasn't surpristed by Trey's actions. \"That's the kind of person Trey is,\" she said. To help make sure she said yes, Trey entered the gym armed with flowers and a poster that read \"Let's Party Like it's 1989,\" a reference to the latest album by Taylor Swift, Ellie's favorite singer. Trey also got the OK from Ellie's parents the night before via text. They were thrilled. \"You just feel numb to those moments raising a special needs child,\"  said Darla Meredith, Ellie's mom. \"You first feel the need to protect and then to overprotect.\" Darla Meredith said Ellie has struggled with friendships since elementary school, but a special program at Eastern called Best Buddies had made things easier for her. She said Best Buddies cultivates friendships between students with and without developmental disabilities and prevents students like Ellie from feeling isolated and left out of social functions. \"I guess around middle school is when kids started to care about what others thought,\" she said, but \"this school, this year has been a relief.\" Trey's future coach at Ball State, James Whitford, said he felt great about the prom-posal, noting that Trey, whom he's known for a long time, often works with other kids . Trey's mother, Shelly Moses, was also proud of her son. \"It's exciting to bring awareness to a good cause,\" she said. \"Trey has worked pretty hard, and he's a good son.\" Both Trey and Ellie have a lot of planning to do. Trey is looking to take up special education as a college major, in addition to playing basketball in the fall. As for Ellie, she can't stop thinking about prom. \"Ellie can't wait to go dress shopping\" her mother said. \"Because I've only told about a million people!\" Ellie interjected.\n",
      "\n",
      "HIGHLIGHTS:\n",
      " College-bound basketball star asks girl with Down syndrome to high school prom .\n",
      "Pictures of the two during the \"prom-posal\" have gone viral .\n"
     ]
    }
   ],
   "source": [
    "## Summarization of one sample\n",
    "sample = dataset['test'][5]\n",
    "print(\"ARTICLE:\\n\", sample['article'])\n",
    "print(\"\\nHIGHLIGHTS:\\n\", sample['highlights'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92e16f4",
   "metadata": {},
   "source": [
    "### Load Pre-trained BART Model and Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c11851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c49a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use GPU if available\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e935b078",
   "metadata": {},
   "source": [
    "### Summarize a News Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0718d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text, max_input=1024, max_output=150):\n",
    "    \"\"\"\n",
    "    Summarize the input text using the BART model. \n",
    "    Args:\n",
    "        text (str): The input text to summarize.\n",
    "        max_input (int): The maximum length of the input text.\n",
    "        max_output (int): The maximum length of the output summary.\n",
    "    Returns:\n",
    "        str: The generated summary.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=max_input, truncation=True) # tokenizes the input text into numerical IDs, returns a PyTorch tensor.\n",
    "    inputs = inputs.to(model.device) # move the input tensor to the same device as the model\n",
    "\n",
    "    summary_ids = model.generate( \n",
    "        inputs,\n",
    "        max_length=max_output,\n",
    "        min_length=40,\n",
    "        length_penalty=2.0,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )       # The generate method takes the input tensor and generates a summary based on the specified parameters.\n",
    "            # max_length: maximum length of the generated summary\n",
    "            # min_length: minimum length of the generated summary\n",
    "            # length_penalty: penalty for longer summaries\n",
    "            # num_beams: number of beams for beam search (used to explore multiple possible outputs)\n",
    "            # early_stopping: stops generation when all beams reach the end token\n",
    "            # skip_special_tokens: skips special tokens in the output (e.g., <pad>, <eos>\n",
    "            # the model generates a summary based on the input text using BART’s sequence generation logic. \n",
    "            #Enables beam search, which explores multiple possible outputs and picks the best.\n",
    "            \n",
    "\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True) # The generated summary IDs are then decoded back into human-readable text using the tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50019c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test the summarization function\n",
    "article = sample['article'] # The article text to summarize\n",
    "summary = summarize_text(article) # The generated summary of the article\n",
    "\n",
    "print(\"MODEL SUMMARY:\\n\", summary)\n",
    "print(\"\\nREFERENCE SUMMARY:\\n\", sample['highlights'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5968057",
   "metadata": {},
   "source": [
    "### ROUGE \n",
    "\n",
    "Rouge stands for Recall-Oriented Understudy for Gisting Evaluation. It compares the overlap between the generated text (prediction) and a reference text (ground truth summary) using n-grams, longest common subsequence (LCS), or skip-grams.\n",
    "\n",
    "| ROUGE Type  | Good Score Range (for summarization) |\n",
    "| ----------- | ------------------------------------ |\n",
    "| **ROUGE-1** | 0.4 – 0.6+                           |\n",
    "| **ROUGE-2** | 0.15 – 0.4                           |\n",
    "| **ROUGE-L** | 0.3 – 0.5+                           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaccd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate ROUGE Score\n",
    "\n",
    "# rogue = evaluate.load(\"rouge\")\n",
    "# rogue_score = rogue.compute(predictions=[summary], references=[sample['highlights']], use_stemmer=True)\n",
    "# print(\"ROUGE-1 Score:\", rogue_score['rouge1'])\n",
    "# print(\"ROUGE-2 Score:\", rogue_score['rouge2'])\n",
    "# print(\"ROUGE-L Score:\", rogue_score['rougeL'])\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "results = rouge.compute(predictions=[summary], references=[sample['highlights']])\n",
    "print(\"ROUGE Evaluation:\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90090b8f",
   "metadata": {},
   "source": [
    "### Fine-Tuning BART model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f337baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6678e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09036ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f252fcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
